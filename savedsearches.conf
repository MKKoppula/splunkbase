[STL_GDC_Websense_Servers_Monitoring]
action.email = 1
action.email.cc = DLCORPEMRCIRT@emerson.com,Matt.Freeman@Emerson.com,CORPSplunk@Emerson.com
action.email.include.results_link = 0
action.email.include.view_link = 0
action.email.inline = 1
action.email.priority = 2
action.email.sendcsv = 1
action.email.sendresults = 1
action.email.to = Ron.Cowan@Emerson.com,DLCORPITInformationSecurityServiceOperations@Emerson.com
action.email.useNSSubject = 1
alert.suppress = 0
alert.track = 0
auto_summarize.dispatch.earliest_time = -1d@h
counttype = number of events
cron_schedule = 34 */6 * * *
disabled = 1
dispatch.earliest_time = -15m@s
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = search
request.ui_dispatch_view = search
search = | tstats count WHERE index=idx_websense sourcetype= websense:cg:kv splunk_server="usstl-splunk-idx*" [| inputlookup websense_servers_stl.csv \
| table host sourcetype] by sourcetype host\
| append [| inputlookup websense_servers_stl.csv | eval count = 0 ] \
| stats max(count) as count by sourcetype host | where count=0\
| eval location=case(match(host,"10.8.*.*"),"St.Louis")\
| eval Status=case(match(host,"10.8.*.*"),"St.Louis Websense gateway server is not forwarding data to Splunk")\
| table sourcetype host location Status

[EMA_GDC_Websense_Servers_Monitoring]
action.email = 1
action.email.cc = DLCORPEMRCIRT@emerson.com,Matt.Freeman@Emerson.com,CORPSplunk@Emerson.com
action.email.include.results_link = 0
action.email.include.view_link = 0
action.email.inline = 1
action.email.priority = 2
action.email.sendcsv = 1
action.email.sendresults = 1
action.email.to = Ron.Cowan@Emerson.com,DLCORPITInformationSecurityServiceOperations@Emerson.com
action.email.useNSSubject = 1
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = 0 */6 * * *
disabled = 1
dispatch.earliest_time = -15m@s
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = search
request.ui_dispatch_view = search
search = | tstats count WHERE index=idx_websense sourcetype="websense:cg:kv" splunk_server="uklon-splunk-idx*" [| inputlookup websense_servers_london.csv \
| table host sourcetype] by sourcetype host \
| append [| inputlookup websense_servers_london.csv | eval count = 0]\
| stats max(count) as count by sourcetype host\
| where count=0\
| eval location=case(match(host,"10.10.*.*"),"London")\
| eval Status=case(match(host,"10.10.*.*"),"London Websense gateway server is not forwarding data to Splunk")\
| table sourcetype host location Status

[Palo Alto Config and System Log Monitoring]
action.email = 1
action.email.cc = Muralikrishna.Koppula@Emerson.com
action.email.include.results_link = 0
action.email.include.trigger = 1
action.email.include.view_link = 0
action.email.inline = 1
action.email.priority = 2
action.email.sendresults = 1
action.email.to = Alexandra.Rust@Emerson.com
action.email.useNSSubject = 1
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = 20 */6 * * *
disabled = 1
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.events.fields = ["blocked","message_id","site","host","source","sourcetype"]
display.general.type = statistics
display.page.search.mode = verbose
display.page.search.tab = statistics
display.visualizations.charting.chart = bar
display.visualizations.custom.type = Splunk_ML_Toolkit.LinesViz
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = search
request.ui_dispatch_view = search
search = | tstats count WHERE index=idx_paloalto [| inputlookup PaloAlto_Config_System_list.csv \
| table host sourcetype] by sourcetype host\
| append [| inputlookup PaloAlto_Config_System_list.csv | eval count = 0]\
| stats max(count) as count by sourcetype host\
| where count=0\
| eval status=case(match(sourcetype,"pan:config"),"Palo Alto device is not forwarding config data to Splunk",\
                   match(sourcetype,"pan:system"),"Palo Alto device is not forwarding system data to Splunk")\
| table sourcetype host status

[GDPR Host Asset Monitoring]
action.email.useNSSubject = 1
alert.track = 0
cron_schedule = */30 * * * *
dispatch.earliest_time = -4d
dispatch.latest_time = +24h
display.general.timeRangePicker.show = 0
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = emr_critical_asset_monitoring
request.ui_dispatch_view = search
schedule_window = auto
search = | tstats count min(_time) as firstTime, max(_time) as lastTime, max(_indextime) as recentTime where _index_earliest=-24h _index_latest=-5m@m (`gdpr_host_filter`) (`sourcetype_filter`) (`index_filter`) (`splunk_server_filter`) by host, sourcetype, index\
| eval host=lower(host)\
| stats sum(count) as count, min(firstTime) as firstTime, max(lastTime) as lastTime, max(recentTime) as recentTime by host, sourcetype, index\
| eval _time=now()-300\
| fields - _time\
| eval hash=md5(host.sourcetype.index)\
| lookup splunk_camp.csv hash OUTPUTNEW _key as _key, firstTime as firstTimekv\
| eval firstTime=if((isnotnull(firstTimekv) AND firstTimekv<firstTime),firstTimekv, firstTime)\
| eval lastUpdated=now()\
| fields host, sourcetype, index, firstTime, lastTime, recentTime, lastUpdated, hash, _key, count\
| outputlookup gdpr_host_camp append=t

[Cisco Firewall Critical Asset Monitoring]
action.email.useNSSubject = 1
alert.track = 0
cron_schedule = */30 * * * *
dispatch.earliest_time = -4d
dispatch.latest_time = +24h
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = emr_critical_asset_monitoring
request.ui_dispatch_view = search
schedule_window = auto
search = | tstats count min(_time) as firstTime, max(_time) as lastTime, max(_indextime) as recentTime where _index_earliest=-24h _index_latest=-5m@m (`cisco_firewall_host_filter`) (`sourcetype_filter`) (`index_filter`) (`splunk_server_filter`) by host, sourcetype, index\
| eval host=lower(host)\
| stats sum(count) as count, min(firstTime) as firstTime, max(lastTime) as lastTime, max(recentTime) as recentTime by host, sourcetype, index\
| eval _time=now()-300\
| fields - _time\
| eval hash=md5(host.sourcetype.index)\
| lookup splunk_camp.csv hash OUTPUTNEW _key as _key, firstTime as firstTimekv\
| eval firstTime=if((isnotnull(firstTimekv) AND firstTimekv<firstTime),firstTimekv, firstTime)\
| eval lastUpdated=now()\
| fields host, sourcetype, index, firstTime, lastTime, recentTime, lastUpdated, hash, _key, count\
| outputlookup cisco_firewall_camp append=t

[DFARS Critical Asset Monitoring]
action.email.useNSSubject = 1
alert.track = 0
cron_schedule = */30 * * * *
dispatch.earliest_time = -4d
dispatch.latest_time = +24h
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = emr_critical_asset_monitoring
request.ui_dispatch_view = search
search = | tstats count min(_time) as firstTime, max(_time) as lastTime, max(_indextime) as recentTime where _index_earliest=-24h _index_latest=-5m@m (`dfars_servers`) (`sourcetype_filter`) (`index_filter`) (`splunk_server_filter`) by host, sourcetype, index\
| eval host=lower(host)\
| stats sum(count) as count, min(firstTime) as firstTime, max(lastTime) as lastTime, max(recentTime) as recentTime by host, sourcetype, index\
| eval _time=now()-300\
| fields - _time\
| eval hash=md5(host.sourcetype.index)\
| lookup splunk_camp.csv hash OUTPUTNEW _key as _key, firstTime as firstTimekv\
| eval firstTime=if((isnotnull(firstTimekv) AND firstTimekv<firstTime),firstTimekv, firstTime)\
| eval lastUpdated=now()\
| fields host, sourcetype, index, firstTime, lastTime, recentTime, lastUpdated, hash, _key, count\
| outputlookup dfars_camp append=t

[DCs AD Monitoring]
action.email.useNSSubject = 1
alert.track = 0
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
display.general.timeRangePicker.show = 0
display.general.type = statistics
display.page.search.mode = verbose
display.page.search.tab = statistics
display.visualizations.charting.chart = bar
display.visualizations.custom.type = sankey_diagram_app.sankey_diagram
display.visualizations.show = 0
request.ui_dispatch_app = emr_critical_asset_monitoring
request.ui_dispatch_view = search
search = | tstats count WHERE index=idx_msad [| inputlookup DCs_monitoring.csv \
| table host index] by index host\
| append [| inputlookup DCs_monitoring.csv | eval count = 0]\
| stats max(count) as count by index host\
| where count=0\
| eval status=case(match(index,"idx_msad"),"Domain Controller is not forwarding ActiveDirectory data to Splunk")\
| table index host status

[Palo_Alto_Critical_Asset_Monitoring]
action.email.useNSSubject = 1
alert.track = 0
cron_schedule = */30 * * * *
dispatch.earliest_time = -4d
dispatch.latest_time = +24h
display.general.timeRangePicker.show = 0
display.general.type = statistics
display.page.search.mode = verbose
display.page.search.tab = statistics
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = emr_critical_asset_monitoring
request.ui_dispatch_view = search
search = | tstats count min(_time) as firstTime, max(_time) as lastTime, max(_indextime) as recentTime where _index_earliest=-20m@m _index_latest=-5m@m (`meta_woot_host_filter`) (`meta_woot_sourcetype_filter`) (`palo_idx_filter`) (`meta_woot_splunk_server_filter`) by host, sourcetype, index\
| eval host=lower(host)\
| stats sum(count) as count, min(firstTime) as firstTime, max(lastTime) as lastTime, max(recentTime) as recentTime by host, sourcetype, index\
| eval _time=now()-300\
| collect sourcetype=meta_woot index=`meta_woot_summary`\
| fields - _time\
| eval hash=md5(host.sourcetype.index)\
| lookup meta_woot hash OUTPUTNEW _key as _key, firstTime as firstTimekv\
| eval firstTime=if((isnotnull(firstTimekv) AND firstTimekv<firstTime),firstTimekv, firstTime)\
| eval lastUpdated=now()\
| fields host, sourcetype, index, firstTime, lastTime, recentTime, lastUpdated, hash, _key, count\
| outputlookup palo_alto_camp append=t

[Proofpoint Log Monitoring]
action.email = 1
action.email.inline = 1
action.email.sendresults = 1
action.email.to = Muralikrishna.Koppula@Emerson.com
action.email.useNSSubject = 1
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = 20 */6 * * *
dispatch.earliest_time = -4h@m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.mode = verbose
display.page.search.tab = statistics
display.visualizations.charting.chart = bar
display.visualizations.custom.type = sankey_diagram_app.sankey_diagram
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = emr_critical_asset_monitoring
request.ui_dispatch_view = search
search = | tstats min(_time) as firstTime, max(_time) as lastTime, max(_indextime) as recentTime earliest(pps_filter_log) as sourcetypes earliest(_time) as etime where sourcetype=pps_filter_log by host sourcetype index\
| join host [| tstats latest(pps_filter_log) as sourcetypes latest(_time) as ltime where index=idx_proofpoint by host sourcetype index]\
| stats min(firstTime) as firstTime, max(lastTime) as lastTime, max(recentTime) as recentTime by host sourcetype index\
| eval hash=md5(host.sourcetype.index)\
| eval convert_late=(1440*60) | eval convert_delayed=(60*60) \
| eval last_time_indexed=case((now()-recentTime)<convert_delayed, "Recent", (now()-recentTime)>convert_late, "Late", (now()-recentTime) > convert_delayed, "Delayed")  \
| eval minutesAgo=round((now() - recentTime)/60,2) | convert ctime(recentTime) ctime(firstTime) ctime(lastTime) ctime(lastUpdated) \
| table index, sourcetype, host, last_time_indexed, minutesAgo, firstTime, lastTime, recentTime \
| search last_time_indexed="*" | rename last_time_indexed AS "Index Level" | sort - minutesAgo | search "Index Level"=Delayed

[Domain Controllers Critical Asset Monitoring]
action.email.useNSSubject = 1
alert.track = 0
cron_schedule = */30 * * * *
dispatch.earliest_time = -4d
dispatch.latest_time = +24h
display.general.timeRangePicker.show = 0
display.general.type = statistics
display.page.search.mode = fast
display.page.search.tab = statistics
display.visualizations.charting.chart = bar
display.visualizations.custom.type = sankey_diagram_app.sankey_diagram
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = emr_critical_asset_monitoring
request.ui_dispatch_view = search
search = | tstats count min(_time) as firstTime, max(_time) as lastTime, max(_indextime) as recentTime where _index_earliest=-60m@m _index_latest=-5m@m (`DCs`) (`sourcetype_filter`) (`index_filter`) (`splunk_server_filter`) by host, sourcetype, index\
| eval host=lower(host), _time=now()-300\
| stats sum(count) as count, min(firstTime) as firstTime, max(lastTime) as lastTime, max(recentTime) as recentTime by host, sourcetype, index\
| fields - count\
| eval hash=md5(host.sourcetype.index)\
| lookup meta_woot hash OUTPUTNEW firstTime as firstTimekv, _key AS _key\
| eval firstTime=if((isnotnull(firstTimekv) AND firstTimekv<firstTime),firstTimekv, firstTime)\
| eval lastUpdated=now()\
| fields host, sourcetype, index, firstTime, lastTime, recentTime, lastUpdated, hash, _key\
| outputlookup ad_camp append=t

[MS_Exchange_Critical_Asset_Monitoring]
action.email.useNSSubject = 1
alert.track = 0
cron_schedule = */30 * * * *
dispatch.earliest_time = -4d
dispatch.latest_time = +24h
display.general.type = statistics
display.page.search.mode = verbose
display.page.search.tab = statistics
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = emr_critical_asset_monitoring
request.ui_dispatch_view = search
search = | tstats count min(_time) as firstTime, max(_time) as lastTime, max(_indextime) as recentTime where _index_earliest=-20m@m _index_latest=-5m@m (`MSExchange`) (`sourcetype_filter`) (`index_filter`) (`splunk_server_filter`) by host, sourcetype, index\
| eval host=lower(host)\
| stats sum(count) as count, min(firstTime) as firstTime, max(lastTime) as lastTime, max(recentTime) as recentTime by host, sourcetype, index\
| eval _time=now()-300\
| collect sourcetype=meta_woot index=`meta_woot_summary`\
| fields - _time\
| eval hash=md5(host.sourcetype.index)\
| lookup meta_woot hash OUTPUTNEW firstTime as firstTimekv, _key AS _key\
| eval firstTime=if((isnotnull(firstTimekv) AND firstTimekv<firstTime),firstTimekv, firstTime)\
| eval lastUpdated=now()\
| fields host, sourcetype, index, firstTime, lastTime, recentTime, lastUpdated, hash, _key\
| outputlookup ms_exchange_camp append=t

[CIRT Critical Asset Monitoring]
action.email.useNSSubject = 1
alert.track = 0
cron_schedule = */30 * * * *
dispatch.earliest_time = -4d
dispatch.latest_time = +24h
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = emr_critical_asset_monitoring
request.ui_dispatch_view = search
search = | tstats count min(_time) as firstTime, max(_time) as lastTime, max(_indextime) as recentTime where _index_earliest=-20m@m _index_latest=-5m@m (`cirt_host_filter`) (`sourcetype_filter`) (`index_filter`) (`splunk_server_filter`) by host, sourcetype, index\
| eval host=lower(host)\
| stats sum(count) as count, min(firstTime) as firstTime, max(lastTime) as lastTime, max(recentTime) as recentTime by host, sourcetype, index\
| eval _time=now()-300\
| fields - _time\
| eval hash=md5(host.sourcetype.index)\
| lookup splunk_camp.csv hash OUTPUTNEW _key as _key, firstTime as firstTimekv\
| eval firstTime=if((isnotnull(firstTimekv) AND firstTimekv<firstTime),firstTimekv, firstTime)\
| eval lastUpdated=now()\
| fields host, sourcetype, index, firstTime, lastTime, recentTime, lastUpdated, hash, _key, count\
| outputlookup cirt_camp append=t

[CIRT_Critical_Asset_Monitoring_Alert]
action.email = 1
action.email.include.view_link = 0
action.email.inline = 1
action.email.priority = 2
action.email.sendresults = 1
action.email.to = CORPEMR-CIRTAnalytics@Emerson.com,Muralikrishna.Koppula@Emerson.com
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = 45 */6 * * *
disabled = 1
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = emr_critical_asset_monitoring
request.ui_dispatch_view = search
search = | tstats count WHERE sourcetype=* [| inputlookup CIRT_CriticalassetMonitoring.csv  | table host sourcetype] by sourcetype host\
| append [| inputlookup CIRT_CriticalassetMonitoring.csv | eval count = 0 ]\
| stats max(count) as count by sourcetype host | where count=0  | table sourcetype host count | rename count as "Count of Events"

[MS:O365:Management_Monitoring]
action.email = 1
action.email.include.results_link = 0
action.email.include.view_link = 0
action.email.inline = 1
action.email.priority = 1
action.email.sendresults = 1
action.email.to = CORPSplunk@Emerson.com,CORPEMR-CIRTAnalytics@Emerson.com
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = 25 */6 * * *
dispatch.earliest_time = -4h@m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_view = search
search = | tstats count WHERE index=idx_office365 sourcetype="o365:management:activity" [| inputlookup office365_workload.csv \
| table host sourcetype] by sourcetype host \
| append [| inputlookup office365_workload.csv | eval count = 0]\
| stats max(count) as count by sourcetype host\
| where count=0\
| eval Status=case(match(host,"usstlecpsplhf11.emrsn.org"),"Office 365 API is not forwarding data to Splunk")\
| table sourcetype host Status

[IPP Critical Asset Monitoring]
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.track = 0
cron_schedule = */30 * * * *
dispatch.earliest_time = -4d
dispatch.latest_time = +24h
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
enableSched = 1
request.ui_dispatch_app = emr_critical_asset_monitoring
request.ui_dispatch_view = search
search = | tstats count min(_time) as firstTime, max(_time) as lastTime, max(_indextime) as recentTime where _index_earliest=-20m@m _index_latest=-5m@m (`ipp`) (`sourcetype_filter`) (`index_filter`) (`splunk_server_filter`) by host, sourcetype, index\
| eval host=lower(host)\
| stats sum(count) as count, min(firstTime) as firstTime, max(lastTime) as lastTime, max(recentTime) as recentTime by host, sourcetype, index\
| eval _time=now()-300\
| fields - _time\
| eval hash=md5(host.sourcetype.index)\
| lookup splunk_camp.csv hash OUTPUTNEW _key as _key, firstTime as firstTimekv\
| eval firstTime=if((isnotnull(firstTimekv) AND firstTimekv<firstTime),firstTimekv, firstTime)\
| eval lastUpdated=now()\
| fields host, sourcetype, index, firstTime, lastTime, recentTime, lastUpdated, hash, _key, count\
| outputlookup ipp append=t

[MSExchange_Servers_Monitoring]
action.email = 1
action.email.include.view_link = 0
action.email.inline = 1
action.email.priority = 2
action.email.sendresults = 1
action.email.to = EM@emerson.com,DLCORPEMRCIRT@emerson.com,CORPSplunk@Emerson.com
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = 0 */6 * * *
dispatch.earliest_time = -4h@m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = search
request.ui_dispatch_view = search
search = | tstats count WHERE index=idx_msexchange [| inputlookup msexchange_splunk_critical_asset_monitoring.csv | table host index] by index host\
| eval From="search"\
| append [| inputlookup msexchange_splunk_critical_asset_monitoring.csv\
| eval count = 0 ]\
| stats max(count) as count by index host\
| where count=0\
| eval status=case(\
match(host,"usstlecpmsgap1c"),"Mailbox, CAS and Transport role server - is not forwarding data to splunk",\
match(host,"USSTLECPMSGAP1D"),"Mailbox, CAS and Transport role server - is not forwarding data to splunk",\
match(host,"usstlecpmsgap1f"),"Mailbox, CAS and Transport role server - is not forwarding data to splunk",\
match(host,"usmtnecrmsgap01"),"Mailbox, CAS and Transport role server - is not forwarding data to splunk",\
match(host,"usmtnecsmsgap01"),"Mailbox, CAS and Transport role server - is not forwarding data to splunk",\
match(host,"USMTNECSMSGAP02"),"Mailbox, CAS and Transport role server - is not forwarding data to splunk",\
match(host,"usstlecpmsgae01"),"Transport role server - is not forwarding data to splunk",\
match(host,"usstlecpmsgae02"),"Transport role server - is not forwarding data to splunk",\
match(host,"usmtnecsmsgae01"),"Transport role server - is not forwarding data to splunk",\
match(host,"USMTNECSMSGAE02"),"Transport role server - is not forwarding data to splunk",\
match(host, "USSTLECPMSGAP25"),"Mailbox, CAS and Transport role server - is not forwarding data to splunk")\
| table index host status

[OpenDNS Log Monitoring]
action.email = 1
action.email.cc = CORPSplunk@Emerson.com
action.email.include.results_link = 0
action.email.include.view_link = 0
action.email.inline = 1
action.email.sendresults = 1
action.email.to = DLCORPEMRCIRT@emerson.com
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.expires = 2h
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = 05 */6 * * 1-5
dispatch.earliest_time = -12h
dispatch.latest_time = now
display.events.fields = ["blocked","message_id","site","host","source","sourcetype"]
display.general.type = statistics
display.page.search.mode = verbose
display.page.search.tab = statistics
display.visualizations.charting.chart = bar
display.visualizations.custom.type = Splunk_ML_Toolkit.LinesViz
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = search
request.ui_dispatch_view = search
search = | tstats count WHERE index=idx_opendns [| inputlookup splunk_camp_opendns.csv\
| table host index] by index host\
| append [| inputlookup splunk_camp_opendns.csv | eval count = 0]\
| stats max(count) as count by index host\
| where count=0\
| eval status=case(match(index,"idx_opendns"),"Splunk is not able to collect data from OpenDNS S3 bucket")\
| table index host status

[cisco:asa_firwall_logs_monitoring]
action.email = 1
action.email.cc = DLCORPEMRCIRT@emerson.com,DLETSGlobalOperations@Emerson.com
action.email.include.view_link = 0
action.email.inline = 1
action.email.priority = 1
action.email.sendresults = 1
action.email.to = CORPSplunk@emerson.com
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 1
alert.suppress.period = 60s
alert.track = 0
counttype = number of events
cron_schedule = 20 */6 * * *
disabled = 1
dispatch.earliest_time = -1h
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_view = search
search = | tstats count WHERE index=idx_firewalls sourcetype=cisco:asa OR sourcetype=firewall splunk_server="*-splunk-idx*" [| inputlookup firewall_cisco_hosts.csv \
| table host sourcetype] by sourcetype host\
| append [| inputlookup firewall_cisco_hosts.csv | eval count = 0 ] \
| stats max(count) as count by sourcetype host | where count=0\
| eval Status=case(match(sourcetype,"cisco:asa"), match(sourcetype, "firewall"),"Firewall logs are not forwarding to Splunk")\
| table sourcetype host Status

[Zedi/MVP Traffic Log Monitoring]
action.email = 1
action.email.cc = CORPSplunk@Emerson.com,Adam.Rothschild@Emerson.com
action.email.include.results_link = 0
action.email.include.trigger_time = 1
action.email.include.view_link = 0
action.email.inline = 1
action.email.priority = 1
action.email.sendresults = 1
action.email.to = GCNetworkOperations@Emerson.com,DLCORPEMRCIRT@emerson.com
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = 05 */6 * * *
disabled = 1
dispatch.earliest_time = -6h@s
dispatch.latest_time = now
display.events.fields = ["blocked","message_id","site","host","source","sourcetype"]
display.general.type = statistics
display.page.search.mode = verbose
display.page.search.tab = statistics
display.visualizations.charting.chart = bar
display.visualizations.custom.type = Splunk_ML_Toolkit.LinesViz
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = search
request.ui_dispatch_view = search
search = | tstats count WHERE index=idx_mvp [| inputlookup zedi_mvp.csv \
| table host index] by index host \
| append [| inputlookup zedi_mvp.csv | eval count = 0]\
| stats max(count) as count by index host\
| where count=0\
| eval status=case(match(host,"173.219.168.22"),"juniper:victoria - firewall data is not forwarding to EMR Splunk",\
                   match(host,"184.69.251.222"),"juniper:fort_st_john - firewall data is not forwarding to EMR Splunk",\
                   match(host,"184.71.240.242"),"juniper:petronet - firewall data is not forwarding to EMR Splunk",\
                   match(host,"204.101.24.120"),"fortigate:calgary - firewall data is not forwarding to EMR Splunk",\
                   match(host,"204.101.24.98"),"juniper:calgary - firewall data is not forwarding to EMR Splunk",\
                   match(host,"206.47.247.62"),"fortigate:edmonton - firewall data is not forwarding to EMR Splunk",\
                   match(host,"207.229.32.150"),"juniper:edmonton - firewall data is not forwarding to EMR Splunk",\
                   match(host,"207.229.32.189"),"fortigate:edmonton - firewall data is not forwarding to EMR Splunk",\
                   match(host,"216.108.161.38"),"juniper:FortNelson - firewall data is not forwarding to EMR Splunk",\
                   match(host,"50.250.148.229"),"sonicalwall:greely - firewall data is not forwarding to EMR Splunk",\
                   match(host,"72.175.201.11"),"sonicwall:riverton - firewall data is not forwarding to EMR Splunk",\
                   match(host,"72.195.174.146"),"juniper:broussard - firewall data is not forwarding to EMR Splunk",\
                   match(host,"72.195.174.147"),"Efortigate:broussard - firewall data is not forwarding to EMR Splunk",\
                   match(host,"96.64.150.213"),"Fortigate:Farmington - firewall data is not forwarding to EMR Splunk")\
| table index host status

[Linux/Unix Performance Data Monitoring  - Collectd issues]
action.email = 1
action.email.cc = Muralikrishna.Koppula@Emerson.com
action.email.include.results_link = 0
action.email.include.view_link = 0
action.email.inline = 1
action.email.sendresults = 1
action.email.to = Ed.Jaegers@emerson.com,Paul.VanCamp@Emerson.com,Brian.Krekel@Emerson.com
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.expires = 3h
alert.suppress = 1
alert.suppress.period = 24h
alert.track = 0
counttype = number of events
cron_schedule = 20 */3 * * *
description = This alert is used to alert the Unix Operations Team in the event that one of their hosts stop sending collectd performance data to Splunk.
dispatch.earliest_time = -60m@m
dispatch.latest_time = now
display.events.type = raw
display.general.type = statistics
display.page.search.mode = verbose
display.page.search.tab = statistics
display.visualizations.charting.chart = line
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = splunk_app_for_emr_linux
request.ui_dispatch_view = search
search = | mstats count where index=mtr_unixcorp AND metric_name=* [| inputlookup collectd_issues.csv | table host] by host\
| append [| inputlookup collectd_issues.csv | fields host | eval count = 0]\
| stats max(count) as count by host\
| where count=0\
| eval server_status=case(match(host,"u|g|c"),"Linux/Unix server is not forwarding performance data to Splunk")\
| eval status = host." - ".server_status\
| stats count by host status server_status\
| table host status

[Titus Log Monitoring]
action.email = 1
action.email.cc = CORPSplunk@Emerson.com
action.email.include.results_link = 0
action.email.include.view_link = 0
action.email.inline = 1
action.email.sendresults = 1
action.email.to = CORPEMR-CIRTAnalytics@Emerson.com,Eric.Falter@Emerson.com,Gage.Cummins@Emerson.com,Nick.Kraabel@Emerson.com,Mark.Cabigas@Emerson.com,Ioan.Muresan@Emerson.com,Gopi.Volukula@Emerson.com
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.expires = 2h
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = 05 */6 * * 1-5
disabled = 1
dispatch.earliest_time = -12h
dispatch.latest_time = now
display.events.fields = ["blocked","message_id","site","host","source","sourcetype"]
display.general.type = statistics
display.page.search.mode = verbose
display.page.search.tab = statistics
display.visualizations.charting.chart = bar
display.visualizations.custom.type = Splunk_ML_Toolkit.LinesViz
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = search
request.ui_dispatch_view = search
search = | tstats count WHERE index=idx_titus [| inputlookup titus_host.csv\
| table host index] by index host\
| append [| inputlookup titus_host.csv | eval count = 0]\
| stats max(count) as count by index host\
| where count=0\
| eval status=case(match(index,"idx_titus"),"Splunk is not able to collect data from Titus database")\
| table index host status

[ms_o365_reporting_messagetrace_log_monitoring]
action.email = 1
action.email.cc = DLCORPEMRCIRT@emerson.com
action.email.include.results_link = 0
action.email.include.view_link = 0
action.email.inline = 1
action.email.sendresults = 1
action.email.to = CORPSplunk@Emerson.com
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = 0 */6 * * *
dispatch.earliest_time = -30h@h
dispatch.latest_time = now
display.events.fields = ["host","source","sourcetype","Message","MessageID","Category","Severity","device"]
display.general.type = statistics
display.page.search.mode = fast
display.page.search.tab = statistics
display.visualizations.charting.chart = area
display.visualizations.custom.type = heat-map-viz.heat-map-viz
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = emr_critical_asset_monitoring
request.ui_dispatch_view = search
search = | tstats count where index=idx_office365 by sourcetype | search sourcetype="ms:o365:reporting:messagetrace" | where count<50

[Palo Alto Traffic Monitoring]
action.email = 1
action.email.cc = CORPSplunk@Emerson.com,Adam.Rothschild@Emerson.com,Brian.Vinyard@Emerson.com
action.email.include.results_link = 0
action.email.include.view_link = 0
action.email.inline = 1
action.email.sendresults = 1
action.email.to = GCNetworkOperations@Emerson.com,DLCORPEMRCIRT@emerson.com
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = 05 */6 * * *
dispatch.earliest_time = -24h
dispatch.latest_time = now
display.events.fields = ["host","source","sourcetype","Message","MessageID","Category","Severity","device"]
display.general.type = statistics
display.page.search.mode = fast
display.page.search.tab = statistics
display.visualizations.charting.chart = area
display.visualizations.custom.type = heat-map-viz.heat-map-viz
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = emr_critical_asset_monitoring
request.ui_dispatch_view = search
search = | tstats count WHERE index=idx_paloalto [| inputlookup Palo_traffic.csv \
| table host sourcetype] by sourcetype host\
| append [| inputlookup Palo_traffic.csv | eval count = 0]\
| stats max(count) as count by sourcetype host\
| where count=0\
| eval status=case(match(sourcetype,"pan:traffic"),"Palo Alto device is not forwarding traffic data to Splunk")\
| table sourcetype host status

[Palo Alto Threat and Traffic Log Monitoring]
action.email = 1
action.email.cc = CORPSplunk@Emerson.com,Adam.Rothschild@Emerson.com
action.email.include.results_link = 0
action.email.include.trigger_time = 1
action.email.include.view_link = 0
action.email.inline = 1
action.email.priority = 1
action.email.sendresults = 1
action.email.to = GCNetworkOperations@Emerson.com,DLCORPEMRCIRT@emerson.com
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = 05 */6 * * *
disabled = 1
dispatch.earliest_time = -15m@s
dispatch.latest_time = now
display.events.fields = ["blocked","message_id","site","host","source","sourcetype"]
display.general.type = statistics
display.page.search.mode = verbose
display.page.search.tab = statistics
display.visualizations.charting.chart = bar
display.visualizations.custom.type = Splunk_ML_Toolkit.LinesViz
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = search
request.ui_dispatch_view = search
search = | tstats count WHERE index=idx_paloalto [| inputlookup paloalto_host_sourcetypes.csv \
| table host sourcetype] by sourcetype host\
| append [| inputlookup paloalto_host_sourcetypes.csv | eval count = 0]\
| stats max(count) as count by sourcetype host\
| where count=0\
| eval status=case(match(sourcetype,"pan:threat"),"Palo Alto device is not forwarding threat data to Splunk",\
                   match(sourcetype,"pan:traffic"),"Palo Alto device is not forwarding traffic data to Splunk")\
| table sourcetype host status

[Palo Alto Threat Monitoring]
action.email = 1
action.email.cc = CORPSplunk@Emerson.com,Adam.Rothschild@Emerson.com,Brian.Vinyard@Emerson.com
action.email.include.results_link = 0
action.email.include.view_link = 0
action.email.inline = 1
action.email.sendresults = 1
action.email.to = GCNetworkOperations@Emerson.com,DLCORPEMRCIRT@emerson.com
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = 05 */6 * * *
dispatch.earliest_time = -24h
dispatch.latest_time = now
display.events.fields = ["host","source","sourcetype","Message","MessageID","Category","Severity","device"]
display.general.type = statistics
display.page.search.mode = fast
display.page.search.tab = statistics
display.visualizations.charting.chart = area
display.visualizations.custom.type = heat-map-viz.heat-map-viz
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = emr_critical_asset_monitoring
request.ui_dispatch_view = search
search = | tstats count WHERE index=idx_paloalto [| inputlookup pan_threat.csv\
| table host sourcetype] by sourcetype host\
| append [| inputlookup pan_threat.csv | eval count = 0]\
| stats max(count) as count by sourcetype host\
| where count=0\
| eval status=case(match(sourcetype,"pan:threat"),"Palo Alto device is not forwarding threat data to Splunk")\
| table sourcetype host status

[Near Critical Index Usage]
action.email = 1
action.email.include.results_link = 0
action.email.include.view_link = 0
action.email.inline = 1
action.email.sendresults = 1
action.email.to = CORPSplunk@Emerson.com
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = 20 */6 * * *
dispatch.earliest_time = -24h
dispatch.latest_time = now
display.events.fields = ["host","source","sourcetype","Message","MessageID","Category","Severity","device"]
display.general.type = statistics
display.page.search.mode = fast
display.page.search.tab = statistics
display.visualizations.charting.chart = area
display.visualizations.custom.type = heat-map-viz.heat-map-viz
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = emr_critical_asset_monitoring
request.ui_dispatch_view = search
search = | rest /services/data/indexes \
| eval indexUsagePerc=(currentDBSizeMB * 100 / maxTotalDataSizeMB ) \
| table title splunk_server currentDBSizeMB maxTotalDataSizeMB indexUsagePerc | where indexUsagePerc > 80

[CrowdStrike logging monitoring]
action.email = 1
action.email.cc = Khoa.Trieu@Emerson.com,Muralikrishna.Koppula@Emerson.com
action.email.include.view_link = 0
action.email.inline = 1
action.email.sendresults = 1
action.email.to = Ricardo.Vides@Emerson.com,James.Nelson@emerson.com
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = 05 */6 * * *
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.events.fields = ["host","source","sourcetype","Message","MessageID","Category","Severity","device"]
display.general.type = statistics
display.page.search.mode = fast
display.page.search.tab = statistics
display.visualizations.charting.chart = area
display.visualizations.custom.type = heat-map-viz.heat-map-viz
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = emr_critical_asset_monitoring
request.ui_dispatch_view = search
search = | tstats count WHERE index=idx_crowdstrike [| inputlookup  crowdstrike_logging.csv \
| table host index] by host index\
| append [| inputlookup  crowdstrike_logging.csv | eval count = 0]\
| stats max(count) as count by host index\
| where count=0\
| eval status=case(match(index,"idx_crowdstrike"),"Splunk is not capturing CrowdStrike data to Splunk")\
| table index host status

[Proofpoint: log ingestion Monitoring]
action.email = 1
action.email.allow_empty_attachment = 0
action.email.include.results_link = 0
action.email.include.view_link = 0
action.email.inline = 1
action.email.sendresults = 1
action.email.to = Muralikrishna.Koppula@Emerson.com
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = 15 * * * *
dispatch.earliest_time = -1h
dispatch.latest_time = now
display.events.fields = ["host","source","sourcetype","Message","MessageID","Category","Severity","device"]
display.general.type = statistics
display.page.search.mode = verbose
display.page.search.tab = statistics
display.visualizations.charting.chart = area
display.visualizations.custom.type = heat-map-viz.heat-map-viz
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = emr_critical_asset_monitoring
request.ui_dispatch_view = search
search = | tstats count WHERE index=idx_proofpoint sourcetype="pps_maillog" [| inputlookup proofpoint_workload.csv \
| table host sourcetype] by sourcetype host \
| append [| inputlookup proofpoint_workload.csv | eval count = 0]\
| stats max(count) as count by sourcetype host\
| where count=0\
| eval Status=case(match(host,"usstlecpsplhf09.emrsn.org"),"Proofpoint API is not forwarding data to Splunk")\
| table sourcetype host Status

[RVO2 Server OS logging monitoring]
action.email = 1
action.email.cc = Khoa.Trieu@Emerson.com,Muralikrishna.Koppula@Emerson.com
action.email.include.view_link = 0
action.email.inline = 1
action.email.sendresults = 1
action.email.to = Ricardo.Vides@Emerson.com,James.Nelson@emerson.com
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = 05 */6 * * *
disabled = 1
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.events.fields = ["host","source","sourcetype","Message","MessageID","Category","Severity","device"]
display.general.type = statistics
display.page.search.mode = fast
display.page.search.tab = statistics
display.visualizations.charting.chart = area
display.visualizations.custom.type = heat-map-viz.heat-map-viz
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = emr_critical_asset_monitoring
request.ui_dispatch_view = search
search = | tstats count WHERE index=idx_winevents [| inputlookup  rvo2_hosts.csv \
| table host index] by host index\
| append [| inputlookup  rvo2_hosts.csv | eval count = 0]\
| stats max(count) as count by host index\
| where count=0\
| eval status=case(match(index,"idx_winevents"),"RVO2 Windows server is not forwarding OS data to Splunk")\
| table index host status

[CIRT_Critical_Asset_Monitoring_Alert_DFARS]
action.email = 1
action.email.include.view_link = 0
action.email.inline = 1
action.email.sendresults = 1
action.email.to = Keith.Broome@Emerson.com,Eli.Krupnik@Emerson.com,Eli.BenMordechai@Emerson.com,Mark.Ebreo@Emerson.com
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = 45 */6 * * *
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = emr_critical_asset_monitoring
request.ui_dispatch_view = search
search = | tstats count WHERE source=* [| inputlookup dfars_servers.csv\
| table host source] by source host\
| append [| inputlookup dfars_servers.csv | eval count = 0 ]\
| stats max(count) as count by source host | where count=0  | table source host count | rename count as "Count of Events"

[Critical_Unix_Servers_Performance_Monitoring]
action.email = 1
action.email.allow_empty_attachment = 0
action.email.cc = CORPSplunk@Emerson.com
action.email.include.results_link = 0
action.email.include.view_link = 0
action.email.inline = 1
action.email.sendresults = 1
action.email.to = itssunixadmins@emrsn.com
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.digest_mode = 0
alert.expires = 3h
alert.suppress = 1
alert.suppress.fields = host
alert.suppress.period = 3h
alert.track = 0
counttype = number of events
cron_schedule = */30 * * * *
dispatch.earliest_time = -30m
dispatch.latest_time = now
display.events.fields = ["host","source","sourcetype","Message","MessageID","Category","Severity","device"]
display.events.type = raw
display.general.type = statistics
display.page.search.mode = fast
display.page.search.tab = statistics
display.visualizations.charting.chart = area
display.visualizations.custom.type = heat-map-viz.heat-map-viz
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = emr_critical_asset_monitoring
request.ui_dispatch_view = search
search = | mstats count where index=mtr_unixcorp AND metric_name=* [| inputlookup SOX_Servers.csv | rename Hostname AS host | table host] by host\
| append [| inputlookup SOX_Servers.csv | rename Hostname AS host | fields host | eval count = 0]\
| stats max(count) as count by host | search host!=*con*\
| where count=0\
| eval server_status=case(match(host,"u|g|c"),"Linux/Unix server is not forwarding performance data to Splunk")\
| eval status = host." - ".server_status\
| stats count by host status server_status\
| search host!=gblonpmprapfe01 AND host!=usmtnz-linfgi* AND host!=usmtnz-dtest* AND host!=usmtnz-linfra*\
| table host status

[IPP Server Monitoring]
action.email = 1
action.email.include.results_link = 0
action.email.include.view_link = 0
action.email.inline = 1
action.email.sendresults = 1
action.email.to = CORPSplunk@Emerson.com
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.expires = 5h
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = 05 */6 * * *
disabled = 1
dispatch.earliest_time = -4h
dispatch.latest_time = now
display.events.fields = ["host","source","sourcetype","Message","MessageID","Category","Severity","device"]
display.general.type = statistics
display.page.search.mode = verbose
display.page.search.tab = statistics
display.visualizations.charting.chart = area
display.visualizations.custom.type = heat-map-viz.heat-map-viz
display.visualizations.type = custom
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = emr_critical_asset_monitoring
request.ui_dispatch_view = search
search = | tstats count WHERE index=* [| inputlookup IPP_Final_Lists.csv \
| table host ] by host\
| append [| inputlookup IPP_Final_Lists.csv | eval count = 0]\
| stats max(count) as count by  host \
| where count=0

[Linux/Unix Performance Data Monitoring]
action.email = 1
action.email.include.results_link = 0
action.email.include.view_link = 0
action.email.inline = 1
action.email.sendresults = 1
action.email.to = Muralikrishna.Koppula@Emerson.com,Ionut.Jula@Emerson.com
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.expires = 3h
alert.suppress = 1
alert.suppress.period = 24h
alert.track = 0
counttype = number of events
cron_schedule = 20 */3 * * *
description = This alert is used to alert the Unix Operations Team in the event that one of their hosts stop sending collectd performance data to Splunk.
disabled = 1
dispatch.earliest_time = -60m@m
dispatch.latest_time = now
display.events.type = raw
display.general.type = statistics
display.page.search.mode = verbose
display.page.search.tab = statistics
display.visualizations.charting.chart = line
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = splunk_app_for_emr_linux
request.ui_dispatch_view = search
search = | mstats count where index=mtr_unixcorp AND metric_name=* [| inputlookup unixroster.csv | rename Hostname AS host | table host] by host\
| append [| inputlookup unixroster.csv | rename Hostname AS host | fields host | eval count = 0]\
| stats max(count) as count by host\
| where count=0\
| eval server_status=case(match(host,"u|g|c"),"Linux/Unix server is not forwarding performance data to Splunk")\
| eval status = host." - ".server_status\
| stats count by host status server_status\
| search host!=gblonpmprapfe01 AND host!=usmtnz-linfgi* AND host!=usmtnz-dtest* AND host!=usmtnz-linfra*\
| table host status

[Cisco ISE logs Monitoring]
action.email = 1
action.email.cc = CORPSplunk@emerson.com
action.email.include.results_link = 0
action.email.include.view_link = 0
action.email.inline = 1
action.email.priority = 1
action.email.sendresults = 1
action.email.to = Darrel.Taylor@emerson.com,Laszlo.Laposi@Emerson.com,rodolfo.malonzo@emerson.com,Kris.Wicklund@Emerson.com
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.suppress.period = 60s
alert.track = 0
counttype = number of events
cron_schedule = 20 */6 * * *
disabled = 1
dispatch.earliest_time = -1h
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_view = search
search = | tstats count WHERE index=idx_ise [| inputlookup CAMP_idx_ise.csv \
| table host index] by index host\
| append [| inputlookup CAMP_idx_ise.csv | eval count = 0 ] \
| stats max(count) as count by index host | where count=0\
| eval Status=case(match(index,"idx_ise"),"Cisco ISE device logs are not forwarding to Splunk")\
| table index host Status

[Domain Controllers Log Monitoring]
action.email = 1
action.email.cc = brian.hollenkamp@emerson.com,CORPSplunk@Emerson.com
action.email.include.results_link = 0
action.email.include.view_link = 0
action.email.inline = 1
action.email.sendresults = 1
action.email.to = DLCORPITInformationSecurityServiceOperations@Emerson.com
action.email.useNSSubject = 1
action.keyindicator.invert = 0
action.makestreams.param.verbose = 0
alert.suppress = 0
alert.track = 0
counttype = number of events
cron_schedule = 08 */6 * * *
dispatch.earliest_time = -4h
dispatch.latest_time = now
display.general.type = statistics
display.page.search.mode = verbose
display.page.search.tab = statistics
display.visualizations.charting.chart = bar
display.visualizations.custom.type = sankey_diagram_app.sankey_diagram
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = emr_critical_asset_monitoring
request.ui_dispatch_view = search
search = | tstats count WHERE index=idx_msad [| inputlookup splunk_dcs.csv \
| table host index] by index host \
| append [| inputlookup splunk_dcs.csv | eval count = 0]\
| search host!=usstlz-pinfde06\
| eval hostname=lower(host) \
| stats max(count) as count by index hostname \
| where count=0 \
| eval status=case(match(index,"idx_msad"),"Domain Controller is not forwarding ActiveDirectory data to Splunk") \
| table index hostname status
